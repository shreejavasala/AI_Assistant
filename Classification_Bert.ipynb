{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, How are you?</td>\n",
       "      <td>Conversation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Open the Calculator</td>\n",
       "      <td>Automation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Computer Science?</td>\n",
       "      <td>Query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, How is it going</td>\n",
       "      <td>Conversation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it going to rain today in Mumabai?</td>\n",
       "      <td>Query</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Text      Category\n",
       "0                       Hi, How are you?  Conversation\n",
       "1                    Open the Calculator    Automation\n",
       "2              What is Computer Science?         Query\n",
       "3                 Hello, How is it going  Conversation\n",
       "4  Is it going to rain today in Mumabai?         Query"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Training_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Query           84\n",
       "Automation      78\n",
       "Conversation    69\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'] = df['Category'].map({\n",
    "    'Conversation' : 0,\n",
    "    'Automation' : 1,\n",
    "    'Query' : 2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, How are you?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Open the Calculator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Computer Science?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, How is it going</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it going to rain today in Mumabai?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Text  Category\n",
       "0                       Hi, How are you?         0\n",
       "1                    Open the Calculator         1\n",
       "2              What is Computer Science?         2\n",
       "3                 Hello, How is it going         0\n",
       "4  Is it going to rain today in Mumabai?         2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Category'], test_size = 0.2, random_state = 42, stratify = df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the train and test data using Bert Tokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_texts(texts, tokenizer, max_len = 128):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        max_length = max_len,\n",
    "        padding = 'max_length', \n",
    "        truncation = True,\n",
    "        return_tensors = 'tf'\n",
    "    )\n",
    "train_encodings = tokenize_texts(X_train, tokenizer)\n",
    "test_encodings = tokenize_texts(X_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow datasets\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    y_train.values\n",
    ")).batch(16)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    y_test.values\n",
    ")).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#loading the model\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 3)\n",
    "\n",
    "#compile the model\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate = 5e-5)\n",
    "model.compile(\n",
    "    optimizer = optimizer, \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    metrics = ['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "12/12 [==============================] - 164s 12s/step - loss: 0.9295 - accuracy: 0.5707 - val_loss: 0.7199 - val_accuracy: 0.8298\n",
      "Epoch 2/3\n",
      "12/12 [==============================] - 135s 11s/step - loss: 0.6045 - accuracy: 0.7989 - val_loss: 0.4276 - val_accuracy: 0.9362\n",
      "Epoch 3/3\n",
      "12/12 [==============================] - 142s 12s/step - loss: 0.3546 - accuracy: 0.9239 - val_loss: 0.2386 - val_accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = test_dataset,\n",
    "    epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 9s 3s/step - loss: 0.2386 - accuracy: 0.9787\n",
      "Test Accuracy:0.978723406791687\n",
      "3/3 [==============================] - 13s 3s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.98        47\n",
      "   macro avg       0.98      0.98      0.98        47\n",
      "weighted avg       0.98      0.98      0.98        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy:{accuracy}\")\n",
    "\n",
    "y_pred = tf.argmax(model.predict(test_dataset)[0], axis = -1)\n",
    "print(classification_report(y_test, y_pred.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert_classification_model/tokenizer_config.json',\n",
       " 'bert_classification_model/special_tokens_map.json',\n",
       " 'bert_classification_model/vocab.txt',\n",
       " 'bert_classification_model/added_tokens.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"bert_classification_model\")\n",
    "tokenizer.save_pretrained(\"bert_classification_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert_classification_model were not used when initializing TFBertForSequenceClassification: ['dropout_113']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at bert_classification_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# to load and reuse\n",
    "\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert_classification_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert_classification_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifying the user input\n",
    "\n",
    "def classify_user_input(input_sentence, model, tokenizer, label_mapping):\n",
    "    encoding = tokenizer(\n",
    "        input_sentence,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    \n",
    "    # Get prediction from the model\n",
    "    prediction = model.predict(dict(encoding))[0]\n",
    "    predicted_label = tf.argmax(prediction, axis=-1).numpy()[0]\n",
    "    \n",
    "    # Map the predicted label to its category name\n",
    "    label_names = {v: k for k, v in label_mapping.items()}\n",
    "    return label_names[predicted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 248ms/step\n",
      "The sentence is classified as : Conversation\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "The sentence is classified as : Automation\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "The sentence is classified as : Query\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "The sentence is classified as : Conversation\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "The sentence is classified as : Query\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "The sentence is classified as : Automation\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "The sentence is classified as : Automation\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "The sentence is classified as : Conversation\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "The sentence is classified as : Conversation\n",
      "1/1 [==============================] - 1s 512ms/step\n",
      "The sentence is classified as : Query\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "The sentence is classified as : Query\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "The sentence is classified as : Conversation\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "The sentence is classified as : Query\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "The sentence is classified as : Query\n",
      "Exited\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {\"Conversation\" : 0, \"Automation\" : 1, \"Query\" : 2}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter your sentence (or type 'exit' to quit):\")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Exited\")\n",
    "        break\n",
    "\n",
    "    category = classify_user_input(user_input, model, tokenizer, label_mapping)\n",
    "    print(f\"The sentence is classified as : {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
